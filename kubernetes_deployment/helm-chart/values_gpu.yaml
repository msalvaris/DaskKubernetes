# nameOverride: dask
# fullnameOverride: dask

scheduler:
  name: scheduler
  image:
    repository: "masalvar/dask-style-transfer-scheduler"
    tag: "version_.003"
    pullPolicy: IfNotPresent
  replicas: 1
  serviceType: "LoadBalancer"
  servicePort: 8786
  resources:
     limits:
       cpu: 6
       memory: 15G
     requests:
       cpu: 2
       memory: 6G

webUI:
  name: webui
  servicePort: 80

worker:
  name: worker
  image:
    repository: "masalvar/dask-style-transfer-worker"
    tag: "version_.003"
    pullPolicy: IfNotPresent
  replicas: 1
  aptPackages: >-
  default_resources:  # overwritten by resource limits if they exist
    cpu: 1
    memory: "4GiB"
  env:
    # - name: EXTRA_CONDA_PACKAGES
    #   value: numba xarray -c conda-forge
    # - name: EXTRA_PIP_PACKAGES
    #   value: s3fs dask-ml --upgrade
  resources:
    limits:
      cpu: 6
      memory: 30G
      nvidia.com/gpu: 1
    requests:
      cpu: 2
      memory: 15G
      nvidia.com/gpu: 1
  volumeMounts:
    - mountPath: "/usr/local/nvidia"
      name: nvidia
    - name: data
      mountPath: /data
    - name: models
      mountPath: /models
    - name: output
      mountPath: /output
  volumes:
    - name: nvidia
      hostPath:
        path: "/usr/local/nvidia"
    - name: data
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecreds
        options:
          container: "data"
          tmppath: /tmp/datablobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"
    - name: models
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecredsmodel
        options:
          container: "models"
          tmppath: /tmp/modelsblobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"
    - name: output
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecreds
        options:
          container: "output"
          tmppath: /tmp/outputblobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"

jupyter:
  name: jupyter
  enabled: true
  image:
    repository: "masalvar/dask-style-transfer-jupyter"
    tag: "version_.003"
    pullPolicy: IfNotPresent
  replicas: 1
  serviceType: "LoadBalancer"
  servicePort: 80
  password: 'sha1:aae8550c0a44:9507d45e087d5ee481a5ce9f4f16f37a0867318c'  # 'dask'
  env:
    # - name: EXTRA_CONDA_PACKAGES
    #   value: numba xarray -c conda-forge
    # - name: EXTRA_PIP_PACKAGES
    #   value: s3fs dask-ml --upgrade
  resources:
     limits:
       cpu: 2
       memory: 30G
     requests:
       cpu: 1
       memory: 15G
  volumeMounts:
    - name: config-volume
      mountPath: /home/jovyan/.jupyter
    - name: data
      mountPath: /data
    - name: models
      mountPath: /models
    - name: output
      mountPath: /output
  volumes:
    - name: data
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecreds
        options:
          container: "data"
          tmppath: /tmp/datablobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"
    - name: models
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecredsmodel
        options:
          container: "models"
          tmppath: /tmp/modelsblobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"
    - name: output
      flexVolume:
        driver: "azure/blobfuse"
        readOnly: false
        secretRef:
          name: blobfusecreds
        options:
          container: "output"
          tmppath: /tmp/outputblobfuse
          mountoptions: "--file-cache-timeout-in-seconds=120"

